{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from TrainHelper import train_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from CNNArchitecture import CNNArchitecture\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Set GPUID in here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "modulationTypes = [\"BPSK\", \"QPSK\", \"8PSK\", \"16QAM\",\n",
    "                   \"64QAM\", \"PAM4\", \"GFSK\", \"CPFSK\", \"BFM\", \"DSBAM\"]\n",
    "\n",
    "label_dict = {'QAM16': 0, 'QAM64': 1, '8PSK': 2, 'WBFM': 3, 'BPSK': 4, 'CPFSK': 5, 'AM-DSB': 6, 'GFSK': 7,\n",
    "              'PAM4': 8, 'QPSK': 9}\n",
    "\n",
    "TrainParams = {}\n",
    "DatasetParams = {}\n",
    "L = 128\n",
    "# Training done for the following batch sizes\n",
    "BS_range = [32]\n",
    "LR = 10 ** -3\n",
    "initialize_type = 'Xavier'  # ['Xavier','Orthogonal']\n",
    "TrainParams['num_epochs'] = 200\n",
    "TrainParams['n_epochs_earlystop'] = 16\n",
    "TrainParams['test_bactchsize'] = 1024\n",
    "# These many iterations are done for every step\n",
    "TrainParams['LRScheduler_stepsize'] = 8\n",
    "# Every r itertaions, the LR is reduced by a multiplicative factor of LRSchedulerDecay\n",
    "TrainParams['LRSchedulerGamma'] = 0.1\n",
    "weight_decay = TrainParams['weight_decay'] = 5e-4\n",
    "TrainParams['optimizer_type'] = 'Adam'\n",
    "TrainParams['validation_size'] = 0.2\n",
    "TrainParams['clip'] = 5\n",
    "\n",
    "DatasetParams['SNRrange'] = np.arange(-20, 21, 2)\n",
    "DatasetParams['Modulationtypes'] = ['QAM16', 'QAM64', '8PSK',\n",
    "                                    'WBFM', 'BPSK', 'CPFSK', 'AM-DSB', 'GFSK', 'PAM4', 'QPSK']\n",
    "DatasetParams['NumClasses'] = len(DatasetParams['Modulationtypes'])\n",
    "DatasetParams['datatype'] = 'RML22'\n",
    "DatasetParams['NumFrames'] = 2000\n",
    "TrainParams['criterion'] = nn.CrossEntropyLoss()\n",
    "TrainParams['computing_device'] = torch.device(\"cuda\")\n",
    "\n",
    "Savemodelfile_location = ''\n",
    "datafilelocation = ''\n",
    "datafilename = datafilelocation + DatasetParams['datatype']\n",
    "\n",
    "\n",
    "for BS in BS_range:\n",
    "    TrainParams['initialize_type'] = initialize_type\n",
    "    TrainParams['L'] = L\n",
    "    TrainParams['BS'] = BS\n",
    "    TrainParams['LR'] = LR\n",
    "\n",
    "    Savemodelfilename = DatasetParams['datatype']\n",
    "\n",
    "    '''\n",
    "        Load dataset from the pickle file. The data is in a dictionary format with keys corresponding \n",
    "        to modulation and SNR. Every dict item in the dictionary contains X items per mod per SNR.\n",
    "        '''\n",
    "    f = open(datafilename, 'rb')\n",
    "    dataset = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    print(\"Dataset loading completed\")\n",
    "    # read the keys - snrs and mods.\n",
    "    snrs, mods = map(lambda j: sorted(\n",
    "        list(set(map(lambda x: x[j], dataset.keys())))), [1, 0])\n",
    "    X = []\n",
    "    lbl = []\n",
    "    for mod in mods:\n",
    "        if mod in DatasetParams['Modulationtypes']:\n",
    "            for snr in snrs:\n",
    "                if snr in DatasetParams['SNRrange']:\n",
    "                    X.append(dataset[(mod, snr)][0:DatasetParams['NumFrames']])\n",
    "                    for i in range(DatasetParams['NumFrames']):\n",
    "                        lbl.append((mod, snr))\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    label_val = list(map(lambda x: lbl[x][0], range(len(lbl))))\n",
    "    label = list(map(lambda x: label_dict[x], label_val))\n",
    "    label = np.array(label)\n",
    "    data = X[:, :, 0:L]\n",
    "    del dataset, X  # deleting large arrays to free up space in RAM.\n",
    "    modelclass = CNNArchitecture\n",
    "\n",
    "    def loadSplitTrain(modelclass, Savemodelfile_location, Savemodelfilename, data, label, TrainParams):\n",
    "\n",
    "        model = modelclass(DatasetParams['NumClasses'])\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, label,\n",
    "                                                            test_size=TrainParams['validation_size'], random_state=1)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                          test_size=TrainParams['validation_size'],\n",
    "                                                          random_state=1)\n",
    "        train_set = {'data': torch.tensor(x_train).float(\n",
    "        ), 'labels': torch.tensor(y_train).float()}\n",
    "        val_set = {'data': torch.tensor(x_val).float(\n",
    "        ), 'labels': torch.tensor(y_val).float()}\n",
    "        del data\n",
    "\n",
    "        ############ ############### Train Model ########################## ##########\n",
    "        ############ ############ ############ ############ ############ ############\n",
    "        model_file = Savemodelfile_location + Savemodelfilename + '_model.pt'\n",
    "        model1, Loss, Accuracy = train_model(\n",
    "            model, model_file, train_set, val_set, TrainParams)\n",
    "        # Save Loss and accuracy plots\n",
    "\n",
    "        plt.figure(1)\n",
    "        epochs = [i for i in range(len(Loss['train']))]\n",
    "        plt.plot(epochs, Loss['train'])\n",
    "        plt.plot(epochs, Loss['valid'])\n",
    "        plt.title('')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(['Training', 'Validation'])\n",
    "        plt.savefig(Savemodelfile_location +\n",
    "                    Savemodelfilename + 'model_loss.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        # plt.show()\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.plot(epochs, Accuracy['train'])\n",
    "        plt.plot(epochs, Accuracy['valid'])\n",
    "        plt.title('')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(['Training', 'Validation'])\n",
    "        plt.savefig(Savemodelfile_location +\n",
    "                    Savemodelfilename + 'model_acc.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    loadSplitTrain(modelclass, Savemodelfile_location,\n",
    "                   Savemodelfilename, data, label, TrainParams)\n",
    "f.close()\n",
    "# Test and plot accuracy versus SNR\n",
    "\n",
    "\n",
    "# Turn off warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "modulationTypes = [\"BPSK\", \"QPSK\", \"8PSK\", \"16QAM\",\n",
    "                   \"64QAM\", \"PAM4\", \"GFSK\", \"CPFSK\", \"BFM\", \"DSBAM\"]\n",
    "\n",
    "label_dict = {'QAM16': 0, 'QAM64': 1, '8PSK': 2, 'WBFM': 3, 'BPSK': 4, 'CPFSK': 5, 'AM-DSB': 6, 'GFSK': 7,\n",
    "              'PAM4': 8, 'QPSK': 9}\n",
    "\n",
    "DatasetParams = {}\n",
    "# L = 128\n",
    "DatasetParams['SNRrange'] = np.arange(-20, 21, 2)\n",
    "DatasetParams['Modulationtypes'] = ['QAM16', 'QAM64', '8PSK',\n",
    "                                    'WBFM', 'BPSK', 'CPFSK', 'AM-DSB', 'GFSK', 'PAM4', 'QPSK']\n",
    "DatasetParams['NumClasses'] = len(DatasetParams['Modulationtypes'])\n",
    "DatasetParams['datatype'] = 'RML22'\n",
    "DatasetParams['NumFrames'] = 2000\n",
    "DatasetParams['frameLength'] = 128\n",
    "TestParams = {}\n",
    "TestParams['validation_size'] = 0.2\n",
    "TestParams['test_BS'] = 1024\n",
    "TestParams['computing_device'] = torch.device(\"cuda\")\n",
    "modulation_reordered = ['BPSK', 'QPSK', '8PSK', '16QAM',\n",
    "                        '64QAM', 'PAM4', 'CPFSK', 'GFSK', 'WBFM', 'AM-DSB']\n",
    "DatasetParams['NumClasses'] = len(DatasetParams['Modulationtypes'])\n",
    "\n",
    "modelfile = DatasetParams['datatype'] + '_model.pt'\n",
    "accuracy = {}\n",
    "dataset = {}\n",
    "\n",
    "\n",
    "def calculate_accuracy(model, data, label, batch_size, computing_device, CM_flag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_samples = data.shape[0]\n",
    "        n_minibatch = int((n_samples + batch_size - 1) / batch_size)\n",
    "        accuracy = 0\n",
    "        I = np.arange(n_samples)\n",
    "        CM_prediction = []\n",
    "        for i in range(n_minibatch):\n",
    "            idx = I[batch_size * i:min(batch_size * (i + 1), n_samples)]\n",
    "            dt = data[idx].to(computing_device)\n",
    "            lbl = label[idx].numpy()\n",
    "            output = model(dt)\n",
    "            output = output.cpu().numpy()\n",
    "            output = np.argmax(output, axis=1)\n",
    "            CM_prediction.extend(list(output))\n",
    "            accuracy += np.sum(output == lbl)\n",
    "        if CM_flag:\n",
    "            return accuracy / n_samples, CM_prediction\n",
    "        else:\n",
    "            return accuracy / n_samples\n",
    "\n",
    "\n",
    "datafilename = DatasetParams['datatype']\n",
    "f = open(datafilename, 'rb')\n",
    "dataset = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "\n",
    "for mod in DatasetParams['Modulationtypes']:\n",
    "    for snr in DatasetParams['SNRrange']:\n",
    "\n",
    "        # Load pre-trained model\n",
    "        modelclass = CNNArchitecture\n",
    "        if 'model' in globals():\n",
    "            # deleting it so that pre-loaded model in previous loop iteration doesnt not mess up this one.\n",
    "            del model\n",
    "        model = modelclass(DatasetParams['NumClasses'])\n",
    "        model.load_state_dict(torch.load(modelfile))\n",
    "        model = model.to(TestParams['computing_device'])\n",
    "        data = dataset[(mod, snr)][0:DatasetParams['NumFrames']]\n",
    "        label = label_dict[mod]*np.ones((data.shape[0],))\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, label,\n",
    "                                                            test_size=TestParams['validation_size'],\n",
    "                                                            random_state=1)\n",
    "        test_data = torch.tensor(x_test).float()\n",
    "        test_label = torch.tensor(y_test).float()\n",
    "        accuracy[(mod, snr)] = calculate_accuracy(model, test_data, test_label,\n",
    "                                                  TestParams['test_BS'],\n",
    "                                                  TestParams['computing_device'], False)\n",
    "snrs, mods = map(lambda j: sorted(\n",
    "    list(set(map(lambda x: x[j], dataset.keys())))), [1, 0])\n",
    "lowSNR = -4\n",
    "highSNR = 21\n",
    "snrrange_confusionmatrix = range(lowSNR, highSNR, 2)\n",
    "X = []\n",
    "lbl = []\n",
    "for mod in mods:\n",
    "    for snr in snrrange_confusionmatrix:\n",
    "        X.append(dataset[(mod, snr)][0:DatasetParams['NumFrames']])\n",
    "        for i in range(DatasetParams['NumFrames']):\n",
    "            lbl.append((mod, snr))\n",
    "del dataset\n",
    "X = np.vstack(X)\n",
    "label_val = list(map(lambda x: lbl[x][0], range(len(lbl))))\n",
    "label = list(map(lambda x: label_dict[x], label_val))\n",
    "label = np.array(label)\n",
    "dataset = X[:, :, 0:DatasetParams['frameLength']]\n",
    "del X\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    dataset, label, test_size=TestParams['validation_size'], random_state=1)\n",
    "test_data = torch.tensor(x_test).float()\n",
    "test_label = torch.tensor(y_test).float()\n",
    "acc_dummy, y_pred = calculate_accuracy(model, test_data, test_label, TestParams['test_BS'],\n",
    "                                       TestParams['computing_device'], True)\n",
    "# Order of modulations are BPSK, QPSK, 8PSK, 16QAM, 64QAM, PAM4, CPFSK, GFSK, QBFM, AM-DSB\n",
    "# We group similar modulation types together in the confusion matrix plots.\n",
    "# Phase senstive ones followed by other digital and then analog modulation types.\n",
    "label_reordered = [4, 9, 2, 0, 1, 8, 5, 7, 3, 6]\n",
    "confusion_mat = confusion_matrix(y_test, y_pred, label_reordered)\n",
    "confusion_mat = confusion_mat.astype(float)\n",
    "\n",
    "accvsSNR = {}\n",
    "plt.figure(1, figsize=(10, 6))\n",
    "snridx = 0\n",
    "accvsSNR = np.zeros((len(DatasetParams['SNRrange']),))\n",
    "for snr in DatasetParams['SNRrange']:\n",
    "    for mod in DatasetParams['Modulationtypes']:\n",
    "        accvsSNR[snridx] = accvsSNR[snridx] + accuracy[mod, snr]\n",
    "    accvsSNR[snridx] = accvsSNR[snridx]/len(DatasetParams['Modulationtypes'])\n",
    "    snridx = snridx+1\n",
    "markerval = 'o'\n",
    "plt.plot(DatasetParams['SNRrange'], accvsSNR, markerval, markersize=10)\n",
    "\n",
    "plt.tick_params(top=False, bottom=True, left=True, right=False, labelleft=True, labelbottom=True, length=8, width=3,\n",
    "                direction='out')\n",
    "# plt.legend(legend_text,fontsize=36)\n",
    "plt.title(\"Test accuracy\", fontsize=20)\n",
    "plt.xlabel(\"SNR in dB\", fontsize=20)\n",
    "plt.ylabel(\"Accuracy\", fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "confusionmat_norm = np.zeros(confusion_mat.shape)\n",
    "for row_idx in np.arange(confusion_mat.shape[0]):\n",
    "    sum = np.sum(confusion_mat[row_idx])\n",
    "    for col_idx in np.arange(confusion_mat.shape[1]):\n",
    "        confusionmat_norm[row_idx][col_idx] = confusion_mat[row_idx][col_idx]/sum\n",
    "plt.figure(1, figsize=(10, 6))\n",
    "\n",
    "im = plt.imshow(confusionmat_norm, cmap='summer',\n",
    "                interpolation='nearest', vmin=0, vmax=1)\n",
    "\n",
    "width, height = confusionmat_norm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        if x == y:\n",
    "\n",
    "            confusionmat_norm_val_2decimalplaces = \"{:0.2f}\".format(\n",
    "                confusionmat_norm[x][y])\n",
    "            if confusionmat_norm_val_2decimalplaces == \"1.00\":\n",
    "                confusionmat_norm_val_2decimalplaces = \"1.0\"\n",
    "            if confusionmat_norm_val_2decimalplaces == \"0.00\":\n",
    "                confusionmat_norm_val_2decimalplaces = \"0\"\n",
    "            plt.annotate(str(confusionmat_norm_val_2decimalplaces), xy=(y, x),\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center', fontsize=12)\n",
    "\n",
    "plt.xticks(np.arange(DatasetParams['NumClasses']),\n",
    "           modulation_reordered, rotation=300, fontsize=14)\n",
    "plt.yticks([], [])\n",
    "plt.title(\"Confusion matrix for SNR above -5 dB\", fontsize=20)\n",
    "plt.xlabel('Predicted Class', fontsize=20)\n",
    "cbar = plt.colorbar(im)\n",
    "tick_font_size = 14\n",
    "cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "plt.yticks(np.arange(DatasetParams['NumClasses']),\n",
    "           modulation_reordered, rotation=0, fontsize=14)\n",
    "plt.ylabel('True Class', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
